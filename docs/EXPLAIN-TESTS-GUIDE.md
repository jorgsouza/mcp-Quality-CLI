# ğŸ” Explain Tests - Guia Completo

## ğŸ“‹ VisÃ£o Geral

O comando `explain-tests` analisa os testes do projeto usando **AST**, **coverage** e **contracts** para gerar explicaÃ§Ãµes detalhadas sobre:

- ğŸ¯ **O que** cada teste estÃ¡ testando
- â“ **Por que** estÃ¡ testando aquele item  
- ğŸ¯ **Para que** estÃ¡ testando (propÃ³sito de negÃ³cio/DORA)
- ğŸ’ª **ForÃ§a dos asserts** (forte/mÃ©dio/fraco)
- âš ï¸ **Code smells** detectados com exemplos de correÃ§Ã£o
- ğŸ“Š **MÃ©tricas KR3a** e DORA

---

## ğŸš€ Como Usar

### CLI

```bash
# AnÃ¡lise bÃ¡sica
quality explain-tests --repo . --product my-app

# Com validaÃ§Ã£o rigorosa
quality explain-tests \
  --repo . \
  --product my-app \
  --fail-on weak \
  --min-diff-coverage 90

# Output customizado
quality explain-tests \
  --repo . \
  --product my-app \
  --format json \
  --out-dir ./custom
```

### MCP

```json
{
  "tool": "explain_tests",
  "arguments": {
    "repo": "/path/to/repo",
    "product": "my-app",
    "format": "md",
    "minDiffCoverage": 80,
    "failOn": "weak"
  }
}
```

---

## ğŸ“Š Outputs Gerados

### 1. test-explanations.json

**LocalizaÃ§Ã£o**: `qa/<product>/tests/analyses/test-explanations.json`

```json
[
  {
    "file": "src/__tests__/auth/validate-user.spec.ts",
    "name": "deve validar usuÃ¡rio com sucesso",
    "testType": "unit",
    "whatItTests": "Testa se validateUser retorna true quando usuÃ¡rio possui credenciais vÃ¡lidas",
    "whyItTests": "Garante comportamento isolado da unidade de cÃ³digo; Previne regressÃµes no comportamento esperado; ValidaÃ§Ãµes especÃ­ficas aumentam confiabilidade",
    "purposeForWhat": "Reduzir CFR (Change Failure Rate) identificando bugs antes do deploy; Reduzir MTTR (Mean Time to Recovery) com diagnÃ³stico rÃ¡pido; Manter confiabilidade e velocidade de entrega (KR3a)",
    "functionUnderTest": "validateUser",
    "given": [
      "Mock do repositÃ³rio de usuÃ¡rios retornando usuÃ¡rio vÃ¡lido",
      "Token JWT vÃ¡lido gerado"
    ],
    "when": "validateUser(userId, token)",
    "then": [
      { "type": "status", "value": 200 },
      { "type": "body.isValid", "value": true },
      { "type": "body.user.id", "value": "userId" }
    ],
    "mocks": ["userRepository.findById", "jwtService.verify"],
    "coverage": {
      "files": ["src/auth/validate-user.ts"],
      "linesCovered": 12,
      "linesTotal": 15,
      "coveredInDiffPct": 80.0
    },
    "contracts": {
      "pact": false,
      "failed": 0,
      "interactions": 0
    },
    "risk": {
      "cuj": "AutenticaÃ§Ã£o de UsuÃ¡rio",
      "level": "mÃ©dio",
      "slo": "99.9% uptime, <200ms latency"
    },
    "assertStrength": "forte",
    "smells": [],
    "suggestions": []
  }
]
```

### 2. TEST-EXPLANATIONS.md

**LocalizaÃ§Ã£o**: `qa/<product>/tests/reports/TEST-EXPLANATIONS.md`

Markdown detalhado com seÃ§Ãµes:
- ğŸ”¬/ğŸ”—/ğŸ­ Emoji por tipo (unit/integration/e2e)
- ğŸ¯ O que testa?
- â“ Por que testa isso?
- ğŸ¯ Para que testa?
- ğŸ“‹ Estrutura Given-When-Then
- ğŸ’ª ForÃ§a dos asserts
- ğŸ“Š Cobertura (PR-aware)
- ğŸ­ Mocks/Spies
- ğŸ¤ Contratos CDC/Pact
- âš ï¸ Code smells com exemplos de correÃ§Ã£o
- ğŸ’¡ SugestÃµes de melhoria

### 3. TEST-QUALITY-SUMMARY.md

**LocalizaÃ§Ã£o**: `qa/<product>/tests/reports/TEST-QUALITY-SUMMARY.md`

SumÃ¡rio executivo com:
- ğŸ¯ Status KR3a (OK/ATENÃ‡ÃƒO/ALERTA)
- ğŸ“ˆ DistribuiÃ§Ã£o de forÃ§a dos testes
- ğŸ¯ Leading Indicators DORA
- ğŸ“Š Impacto esperado em CFR/MTTR/DF/LTC

### 4. test-quality-metrics.json

**LocalizaÃ§Ã£o**: `qa/<product>/tests/analyses/test-quality-metrics.json`

```json
{
  "assertStrongPct": 64.2,
  "assertMediumPct": 28.5,
  "assertWeakPct": 7.3,
  "diffCoveredPct": 83.5,
  "contractsProtectedPct": 78.0,
  "weakTestsInDiffPct": 6.7,
  "criticalEndpointsWithoutContract": 2,
  "suspectedFlakyPct": 1.3,
  "diagnosticAssertsPct": 92.7,
  "totalTests": 147,
  "testsWithAsserts": 145,
  "testsWithoutAsserts": 2
}
```

---

## ğŸ¯ Code Smells Detectados

O `explain-tests` identifica 4 tipos de code smells e fornece **exemplos prÃ¡ticos** de correÃ§Ã£o:

### 1. ğŸš¨ Teste sem Asserts (CRITICAL)

**DescriÃ§Ã£o**: Teste nÃ£o valida nenhum comportamento  
**Impacto**: Teste sempre passa (falso positivo). Bugs nÃ£o sÃ£o detectados. Coverage inflado artificialmente.

**âŒ Antes (Problema):**

```typescript
it('deve processar dados', () => {
  const result = processData(input);
  // NÃ£o valida nada! ğŸš¨
});
```

**âœ… Depois (Corrigido):**

```typescript
it('deve processar dados', () => {
  const result = processData(input);
  
  // Validar retorno
  expect(result).toBeDefined();
  expect(result.status).toBe('success');
  
  // Validar dados processados
  expect(result.data).toHaveLength(3);
  expect(result.data[0]).toHaveProperty('id');
  
  // Validar efeitos colaterais
  expect(result.timestamp).toBeGreaterThan(0);
});
```

### 2. âš ï¸ Excesso de Mocks (HIGH)

**DescriÃ§Ã£o**: Teste muito acoplado Ã  implementaÃ§Ã£o  
**Impacto**: Teste frÃ¡gil que quebra com mudanÃ§as internas. Dificulta refatoraÃ§Ã£o.

**âŒ Antes (Problema):**

```typescript
it('should send email', () => {
  const mockDb = vi.fn();
  const mockLogger = vi.fn();
  const mockEmailService = vi.fn();
  const mockQueue = vi.fn();
  const mockCache = vi.fn(); // 5Âº mock! ğŸš¨
  const mockMetrics = vi.fn();
  
  sendEmailWithLogging(data, mockDb, mockLogger, ...);
  
  expect(mockDb).toHaveBeenCalled();
  expect(mockLogger).toHaveBeenCalled();
  // Testando demais a implementaÃ§Ã£o!
});
```

**âœ… Depois (Corrigido):**

```typescript
it('should send email', async () => {
  // Mock apenas APIs externas (nÃ£o controlÃ¡veis)
  const mockEmailProvider = vi.fn().mockResolvedValue({ sent: true });
  
  // Use implementaÃ§Ãµes reais para o resto
  const result = await emailService.send({
    to: 'test@example.com',
    subject: 'Test',
    provider: mockEmailProvider
  });
  
  // Valide o COMPORTAMENTO, nÃ£o a implementaÃ§Ã£o
  expect(result.sent).toBe(true);
  expect(mockEmailProvider).toHaveBeenCalledWith(
    expect.objectContaining({ to: 'test@example.com' })
  );
});
```

### 3. ğŸŸ¡ Teste de Erro sem try-catch (MEDIUM)

**DescriÃ§Ã£o**: ValidaÃ§Ã£o genÃ©rica de exceÃ§Ãµes  
**Impacto**: NÃ£o valida tipo, mensagem ou causa do erro. Error handling superficial.

**âŒ Antes (Problema):**

```typescript
it('should throw error on invalid input', () => {
  expect(() => validateInput(invalidData)).toThrow();
  // NÃ£o valida QUAL erro! ğŸš¨
});
```

**âœ… Depois (Corrigido):**

```typescript
it('should throw ValidationError with specific message', async () => {
  try {
    await validateInput(invalidData);
    fail('Deveria ter lanÃ§ado ValidationError');
  } catch (error) {
    // Validar tipo do erro
    expect(error).toBeInstanceOf(ValidationError);
    
    // Validar mensagem especÃ­fica
    expect(error.message).toBe('Email is required');
    
    // Validar cÃ³digo de erro
    expect(error.code).toBe('VALIDATION_ERROR');
    
    // Validar campos invÃ¡lidos
    expect(error.fields).toContain('email');
  }
});
```

### 4. â„¹ï¸ Teste Muito Longo (LOW)

**DescriÃ§Ã£o**: Teste viola Single Responsibility Principle  
**Impacto**: DifÃ­cil de entender e debugar. Provavelmente testa mÃºltiplas coisas.

**âœ… Como corrigir**: Quebrar em mÃºltiplos testes menores (10-30 linhas cada), usar `beforeEach` para setup compartilhado, agrupar com `describe()`.

---

## ğŸ¯ MÃ©tricas KR3a & DORA

### KR3a Guardrails

| Guardrail | Meta | Impacto |
|-----------|------|---------|
| Testes Fracos no Diff | â‰¤ 5% | Reduz CFR |
| Diff Coverage | â‰¥ 80% | MantÃ©m DF/LTC |
| Contracts Protected | â‰¥ 90% | Reduz falhas de integraÃ§Ã£o |
| Diagnostic Asserts | â‰¥ 90% | Reduz MTTR |

### Status KR3a

- **OK** âœ…: Todos os guardrails atendidos
- **ATENÃ‡ÃƒO** âš ï¸: 1 guardrail violado ou weakTests â‰¤ 10%
- **ALERTA** ğŸš¨: 2+ guardrails violados

### DORA Leading Indicators

- **CFR (Change Failure Rate)**: Testes fortes + contracts previnem bugs em produÃ§Ã£o
- **MTTR (Mean Time to Recovery)**: Asserts diagnÃ³sticos aceleram debug
- **DF (Deploy Frequency)**: Coverage adequado mantÃ©m velocidade
- **LTC (Lead Time for Changes)**: ConfianÃ§a para deploy rÃ¡pido

---

## ğŸ“‹ Flags DisponÃ­veis

| Flag | DescriÃ§Ã£o | PadrÃ£o |
|------|-----------|--------|
| `--repo` | Caminho do repositÃ³rio | `.` |
| `--product` | Nome do produto | ObrigatÃ³rio |
| `--format` | Formato de saÃ­da (`md` ou `json`) | `md` |
| `--out-dir` | DiretÃ³rio de saÃ­da customizado | `qa/<product>/tests/` |
| `--base-branch` | Branch base para diff coverage | `main` |
| `--min-diff-coverage` | Coverage mÃ­nimo no diff (%) | `80` |
| `--min-asserts` | Asserts mÃ­nimos por teste | `1` |
| `--fail-on` | Falhar quando (`weak` ou `none`) | `none` |

---

## ğŸ’¡ Casos de Uso

### 1. AnÃ¡lise RÃ¡pida (Dev Local)

```bash
# Ver qualidade dos testes atuais
quality explain-tests --repo . --product my-app
cat qa/my-app/tests/reports/TEST-QUALITY-SUMMARY.md
```

### 2. Gate de Pull Request

```bash
# Bloquear PR com testes fracos
quality explain-tests \
  --repo . \
  --product my-app \
  --fail-on weak \
  --min-diff-coverage 80

# Exit code: 0 = pass, 1 = fail
```

### 3. Onboarding de Desenvolvedores

```bash
# Gerar documentaÃ§Ã£o completa dos testes
quality explain-tests --repo . --product my-app

# Novo dev lÃª:
# - qa/my-app/tests/reports/TEST-EXPLANATIONS.md
#   â†’ Entende O QUE cada teste faz
#   â†’ Entende POR QUE existe
#   â†’ Entende PARA QUE serve (negÃ³cio)
```

### 4. RefatoraÃ§Ã£o Guiada

```bash
# Identificar testes problemÃ¡ticos
quality explain-tests --repo . --product my-app

# Priorizar correÃ§Ãµes por:
# 1. Smells CRITICAL (teste sem asserts)
# 2. Smells HIGH (excesso de mocks)
# 3. Testes no diff com assertStrength fraco
```

---

## ğŸ”— IntegraÃ§Ã£o com Outras Features

### Com `quality analyze`

```bash
# 1. Gerar coverage + contracts primeiro
quality analyze --repo . --product my-app --mode full

# 2. Explicar testes (usa coverage/contracts)
quality explain-tests --repo . --product my-app

# Resultado: testes enriquecidos com:
# - coveredInDiffPct (do diff-coverage.json)
# - contracts.pact/failed (do contracts-verify.json)
# - risk.cuj/level (do risk-register.json)
```

### Com Dashboard

```bash
# Gerar + visualizar
quality explain-tests --repo . --product my-app
xdg-open qa/my-app/tests/analyses/dashboard.html

# Dashboard exibe:
# - Card "Test Quality (KR3a)"
# - MÃ©tricas de forÃ§a dos testes
# - Indicadores DORA
```

---

## âœ… Checklist de Qualidade

Use este checklist apÃ³s cada anÃ¡lise:

- [ ] `assertStrongPct` â‰¥ 70%?
- [ ] `assertWeakPct` â‰¤ 10%?
- [ ] `diffCoveredPct` â‰¥ 80%?
- [ ] `weakTestsInDiffPct` â‰¤ 5%?
- [ ] `contractsProtectedPct` â‰¥ 90% (se aplicÃ¡vel)?
- [ ] `testsWithoutAsserts` = 0?
- [ ] Todos os smells CRITICAL corrigidos?
- [ ] CUJs crÃ­ticos tÃªm testes fortes?

**Se algum item falhou**: Consulte `TEST-EXPLANATIONS.md` para ver os testes problemÃ¡ticos e seus exemplos de correÃ§Ã£o.

---

## ğŸš€ PrÃ³ximas Features (Futuro)

- [ ] Suporte a Python/Go/Java AST parsing
- [ ] DetecÃ§Ã£o de flaky tests
- [ ] RecomendaÃ§Ã£o automÃ¡tica de testes faltantes
- [ ] IntegraÃ§Ã£o com AI para gerar correÃ§Ãµes
- [ ] Property-based test detection
- [ ] Performance test analysis

---

**VersÃ£o**: v2.0  
**Ãšltima AtualizaÃ§Ã£o**: 2025-11-04  
**Status**: âœ… Production Ready

